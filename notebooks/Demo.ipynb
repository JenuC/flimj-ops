{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLA and RLD Fitting Op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add required dependencies and read the time-resolved transient data from *input.sdt*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added new repo: imagej.public\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d218696d-7c5e-4c2e-94bf-54399cbfe672",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0627e9bd-026e-4347-ad59-bc7b1c8e713d",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a8eb52-74dd-436c-babf-2b39ca1b87bb",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541c3889-01d1-479d-9d63-71366c789dff",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf83949-8016-4a9e-9442-3817b70207ed",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46b4f03-2786-46bf-8c8a-fcd98b8884aa",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbbd574-75c5-4e35-9850-899b91dacd70",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading SDT header\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "input.sdt"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%classpath config resolver imagej.public https://maven.imagej.net/content/groups/public\n",
    "%classpath add mvn io.scif scifio-lifesci 0.8.0\n",
    "%classpath add mvn net.imagej imagej 2.0.0-rc-67\n",
    "%classpath add mvn net.imglib2 imglib2-roi 0.5.2\n",
    "%classpath add mvn org.scijava native-lib-loader 2.3.0\n",
    "%classpath add jar ../target/slim-curve-1.0.0-SNAPSHOT.jar\n",
    "%classpath add jar ../target/slim-curve-1.0.0-SNAPSHOT-natives-windows_64.jar\n",
    "%classpath add jar ../target/slim-plugin-0.1.0-SNAPSHOT.jar\n",
    "\n",
    "import net.imagej.ImageJ\n",
    "\n",
    "ij = new ImageJ()\n",
    "op = ij.op()\n",
    "nb = ij.notebook()\n",
    "sdt = ij.scifio().datasetIO().open(\"../input.sdt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RADisplay@2b442e10"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RADisplay {\n",
    "\n",
    "    private encoder = java.util.Base64.getEncoder()\n",
    "\n",
    "    private nb\n",
    "\n",
    "    // an imagej notebook\n",
    "    public RADisplay(nb) {\n",
    "        this.nb = nb\n",
    "    }\n",
    "\n",
    "    // BufferedImage to Base64 String\n",
    "    public String BI2Base64(img) {\n",
    "        byte[] buf = com.twosigma.beakerx.util.Images.encode(img, \"PNG\")\n",
    "        return encoder.encodeToString(buf)\n",
    "    }\n",
    "\n",
    "    // BufferedImage to URI\n",
    "    public String BI2Base64URI(img) {\n",
    "        return \"data:image/png;base64,\" + BI2Base64(img)\n",
    "    }\n",
    "\n",
    "    // an alternative to TableDisplay\n",
    "    public Object displayTable(List<List> table) {\n",
    "        def style = \"<style>table { border-collapse: collapse; } th, td { text-align: center; padding: 4px; } tr:nth-child(even) {background-color: #f2f2f2;}</style>\"\n",
    "        def head = \"<table border='1'>\"\n",
    "        def tail = \"</table>\"\n",
    "        def html = style + head\n",
    "        for (row in table) {\n",
    "            html += '<tr>'\n",
    "            for (col in row) {\n",
    "                html += '<th>'\n",
    "                html += col instanceof net.imglib2.RandomAccessibleInterval? \"<img src='\" + BI2Base64URI(nb.display(col)) + \"'>\" : col\n",
    "                html += '</th>'\n",
    "            }\n",
    "            html += '</tr>'\n",
    "        }\n",
    "        def result = new com.twosigma.beakerx.widget.HTML()\n",
    "        result.value = html\n",
    "        return result\n",
    "    }\n",
    "}\n",
    "\n",
    "rad = new RADisplay(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acquired dataset is a 4-dimensional image with metadata:<br>\n",
    "*(Only the one channel is shown)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading SDT header\n",
      "Dim #0: size: 128, type: X\n",
      "Dim #1: size: 128, type: Y\n",
      "Dim #2: size:  64, type: Lifetime\n",
      "Dim #3: size:  16, type: Spectra\n",
      "Time base: 12.500000, number of bins: 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5a008a-84bf-4b9a-b173-0c3b5b2f3106",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io.scif.lifesci.SDTFormat\n",
    "\n",
    "sdtReader = new SDTFormat.Reader()\n",
    "sdtReader.setContext(ij.getContext())\n",
    "sdtReader.setSource(\"../input.sdt\")\n",
    "sdtMetadata = sdtReader.getMetadata()\n",
    "\n",
    "// display the axis type of each dimension\n",
    "for (d = 0; d < sdt.numDimensions(); d++) {\n",
    "    printf(\"Dim #%d: size: %3d, type: %s\\n\", d, sdt.dimension(d), sdt.axis(d).type())\n",
    "}\n",
    "\n",
    "timeBase = sdtMetadata.getTimeBase()\n",
    "timeBins = sdtMetadata.getTimeBins()\n",
    "\n",
    "printf(\"Time base: %6f, number of bins: %d\\n\", timeBase, timeBins)\n",
    "\n",
    "// show the intensity of channel 12 at frame 10\n",
    "tFixed = op.transform().hyperSliceView(sdt, 3, 12)\n",
    "sample = op.transform().hyperSliceView(tFixed, 2, 10)\n",
    "\n",
    "cStart = 6\n",
    "cEnd = 15\n",
    "tStart = 6\n",
    "tEnd = 18\n",
    "table = [[]]\n",
    "table[0][0] = \"Spectrum\\\\Time\"\n",
    "for (t in (tStart..tEnd)) {\n",
    "    table[0][t - tStart + 1] = t\n",
    "}\n",
    "for (c in (cStart..cEnd)) {\n",
    "    table[c - cStart + 1] = []\n",
    "    table[c - cStart + 1][0] = c\n",
    "    tFixed = op.transform().hyperSliceView(sdt, 3, c)\n",
    "    for (t in (tStart..tEnd)) {\n",
    "        sample = op.transform().hyperSliceView(tFixed, 2, t)\n",
    "        table[c - cStart + 1][t - tStart + 1] = sample\n",
    "    }\n",
    "}\n",
    "table\n",
    "rad.displayTable(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the fitting ops takes the transient data (`in`), the fitting parameter (`params`) and the Lifetime axis index (`lifetimeAxis`). The rigion of interest (`roi`) and binning settings (`binningKnl`, `binningAxes`) are optional (see below). An output image will be automatically created if a pre-allocated one (`out`) is not provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.help(\"slimFitter.fitRAI.rld\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to fitting, we set up some fitting parameters specifying how the fitting is done, as described below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import net.imagej.slim.utils.FitParams\n",
    "import slim.FitFunc\n",
    "import slim.NoiseType\n",
    "import slim.RestrainType\n",
    "\n",
    "// create a new fitting parameter set\n",
    "param = new FitParams()\n",
    "// the iterative fitting routine will stop when chi-squared improvement is less than param.chisq_delta\n",
    "param.chisq_delta = 0.0001f\n",
    "// the confidence interval when calculating the error axes (95% here)\n",
    "param.chisq_percent = 95\n",
    "// the routine will also stop when chi-squared < param.chisq_target\n",
    "param.chisq_target = 1\n",
    "// when does the decay start and end?\n",
    "param.fitStart = 9\n",
    "param.fitEnd = 20\n",
    "// the deacy model to use, in this case y(t) = Z + A * e^(-t / TAU)\n",
    "param.fitFunc = FitFunc.GCI_MULTIEXP_TAU\n",
    "// assume the data noise follows a Poisson distribution\n",
    "param.noise = NoiseType.NOISE_GAUSSIAN_FIT\n",
    "// the standard deviation at each data point in y\n",
    "// NB: if NoiseType.NOISE_GIVEN is used, param.sig should be passed in\n",
    "param.sig = null\n",
    "// initial Z, A and TAU\n",
    "param.param = [ 0, 0, 0 ]\n",
    "// all three parameters above will be fitted\n",
    "param.paramFree = [ true, true, true ]\n",
    "// use the default restrain type\n",
    "param.restrain = RestrainType.ECF_RESTRAIN_DEFAULT\n",
    "// the time difference between two consecutive bins (ns)\n",
    "param.xInc = timeBase / timeBins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once everything is set up, the fitting routine can be started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// spin!\n",
    "rldFitted = ij.op().run(\"slimFitter.fitRAI.rld\", null, sdt, param, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will generate an image of the same size as the input dataset in every dimensions except for Lifetime. The Lifetime axis has now become the _\"Parameter axis\"_, with each value denoting a fitted parameter. E.g. (2, 1, 0, 10) is the _Z_ for coordinate X=2, Y=1, Spectra=10; (2, 1, 1, 10) is the *A* for coordinate X=2, Y=1, Spectra=10 and so on. The following shows the fitted _TAU_ values of Spectra channel 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// show the TAUs of channel 12\n",
    "tFixed = op.transform().hyperSliceView(rldFitted, 3, 12)\n",
    "sample = op.transform().hyperSliceView(tFixed, 2, 2)\n",
    "nb.display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the RLD fitting op can be used to quickly but roughly estimate the model parameters, another MLA fit can be used with it in conjunction to give more accurate results (lower chi-squared). To do that, either `param.param` should be set to an well approximated initial values, or `param.paramRA` should be set to a per-pixel estimation provided by an RLD fit with the same fitting parameters. MLA fit can easily fail if the initial values are way off the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// param.paramRA can be used to pass pixel-specific estimated parameter (Z, A, TAU) values to\n",
    "// the MLA fitting routine, which will fail on inaccurate initial values\n",
    "param.paramRA = rldFitted\n",
    "mlaFitted = ij.op().run(\"slimFitter.fitRAI.mla\", null, sdt, param, 2)\n",
    "\n",
    "tFixed = op.transform().hyperSliceView(mlaFitted, 3, 12)\n",
    "sample = op.transform().hyperSliceView(tFixed, 2, 2)\n",
    "nb.display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, instead of the whole dataset, only part of the image (e.g. the region near the nucleus) are of our interest. By specifying the `roi` parameter, we neglect unwanted parts outside of it during fitting. This greatly improves the running time on large images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import net.imglib2.roi.geom.real.OpenWritableBox\n",
    "\n",
    "// X, Y, Spectra bounds\n",
    "min = [ 40, 40, 10 ]\n",
    "max = [ 87, 87, 15 ]\n",
    "\n",
    "// define our region of interest, in this case [40, 87] * [40, 87], channel 10 through 15\n",
    "roi = new OpenWritableBox([ min[0] - 1, min[1] - 1, min[2] - 1 ] as double[], [ max[0] + 1, max[1] + 1, max[2] + 1 ] as double[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the fitting routine the same way as before but with the `roi` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// spin!\n",
    "rldFitted = ij.op().run(\"slimFitter.fitRAI.rld\", null, sdt, param, 2, roi)\n",
    "\n",
    "param.paramRA = rldFitted\n",
    "mlaFitted = ij.op().run(\"slimFitter.fitRAI.mla\", null, sdt, param, 2, roi)\n",
    "\n",
    "// show the TAUs of channel 12\n",
    "tFixed = op.transform().hyperSliceView(mlaFitted, 3, 12)\n",
    "sample = op.transform().hyperSliceView(tFixed, 2, 0)\n",
    "nb.display(sample)\n",
    "// // ij.notebook().display(paramImg)\n",
    "// // ui.show(paramImg)\n",
    "// // ij.op().getPlugins()\n",
    "// spectraSlices = [:]\n",
    "// tFixed = op.transform().hyperSliceView(paramImg, 2, 12)\n",
    "// a = op.transform().hyperSliceView(tFixed, 2, 10)\n",
    "// for (i = 0; i < 1; i++) {\n",
    "//     spectraSlices.put(\"Chanel #\" + i, paramImg)\n",
    "// //     nb.display(ij.op().transform().hyperSliceView(tFixed, 2, 10))\n",
    "// }\n",
    "\n",
    "// // [spectraSlices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the results above, all other regions outside the box is neglected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, for example, the dataset is too noisy and/or the average intensity is too low, binning of neighboring pixels in the XY-plane can be enabled by specifying `binningKnl` and `binningAxes`.<br>\n",
    "`binningKnl` defines a **kernel** for each pixel **with the given size and shape** (e.g. a 3\\*3 square) within which averaging of the neighborhood will be performed to replace the central value.<br>\n",
    "`binningAxes` specifies the axis along which the kernel is expanded. In most cases, those are the **indices of X and Y axes**. One can include the Spectra axis to take pixels in the XY-neighborhood but in near-by spectra channels into account, but it may not make sense to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import net.imglib2.algorithm.neighborhood.RectangleShape\n",
    "\n",
    "// NB: the kernel should not include the center, as specifed by `skipCenter=true` in this case.\n",
    "binningShape = new RectangleShape(1, true)\n",
    "// X and Y axes\n",
    "binningAxes = [ 0, 1 ] as int[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// spin!\n",
    "rldFitted = ij.op().run(\"slimFitter.fitRAI.rld\", null, sdt, param, 2, roi, binningShape, binningAxes)\n",
    "\n",
    "param.paramRA = rldFitted\n",
    "mlaFitted = ij.op().run(\"slimFitter.fitRAI.mla\", null, sdt, param, 2, roi, binningShape, binningAxes)\n",
    "\n",
    "// show the TAUs of channel 12\n",
    "tFixed = op.transform().hyperSliceView(mlaFitted, 3, 12)\n",
    "sample = op.transform().hyperSliceView(tFixed, 2, 0)\n",
    "nb.display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: although binning may be useful in smoothing out noises, the resolution of the result may be lowered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Groovy",
   "language": "groovy",
   "name": "groovy"
  },
  "language_info": {
   "codemirror_mode": "groovy",
   "file_extension": ".groovy",
   "mimetype": "",
   "name": "Groovy",
   "nbconverter_exporter": "",
   "version": "2.4.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
